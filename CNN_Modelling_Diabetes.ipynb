{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bURNyx3B59Bm"
   },
   "outputs": [],
   "source": [
    "#Importiong the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importing the modelling libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "F4SlU-h18oLb",
    "outputId": "615fa69d-7792-4eb8-ccef-612106d1481e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.2</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>17.37</td>\n",
       "      <td>6.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Male</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>former</td>\n",
       "      <td>27.83</td>\n",
       "      <td>5.7</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>35.42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Female</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>22.43</td>\n",
       "      <td>6.6</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
       "0      Female  80.0             0              1           never  25.19   \n",
       "1      Female  54.0             0              0         No Info  27.32   \n",
       "2        Male  28.0             0              0           never  27.32   \n",
       "3      Female  36.0             0              0         current  23.45   \n",
       "4        Male  76.0             1              1         current  20.14   \n",
       "...       ...   ...           ...            ...             ...    ...   \n",
       "99995  Female  80.0             0              0         No Info  27.32   \n",
       "99996  Female   2.0             0              0         No Info  17.37   \n",
       "99997    Male  66.0             0              0          former  27.83   \n",
       "99998  Female  24.0             0              0           never  35.42   \n",
       "99999  Female  57.0             0              0         current  22.43   \n",
       "\n",
       "       HbA1c_level  blood_glucose_level  diabetes  \n",
       "0              6.6                  140         0  \n",
       "1              6.6                   80         0  \n",
       "2              5.7                  158         0  \n",
       "3              5.0                  155         0  \n",
       "4              4.8                  155         0  \n",
       "...            ...                  ...       ...  \n",
       "99995          6.2                   90         0  \n",
       "99996          6.5                  100         0  \n",
       "99997          5.7                  155         0  \n",
       "99998          4.0                  100         0  \n",
       "99999          6.6                   90         0  \n",
       "\n",
       "[100000 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the dataset\n",
    "df_pred= pd.read_csv('Data/diabetes_prediction_dataset.csv')\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nG9zjdRr-ZAV",
    "outputId": "af07b673-4be3-4b3b-8617-3840aa53c8ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying the number of labels\n",
    "df_pred['diabetes'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9FDw7OFT8nM"
   },
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FLVqfglWuo99",
    "outputId": "7b1f975b-58b1-4c8f-ab5e-5c70b7c983ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for the rows and columns in the prediction dataset\n",
    "df_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGdCDw6mftsd"
   },
   "source": [
    "There are 9 columns and 100000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FCLuu2V1u4N5",
    "outputId": "da9688cc-eafe-4d47-ef90-06323fd881a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history',\n",
       "       'bmi', 'HbA1c_level', 'blood_glucose_level', 'diabetes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displaying the prediction columns\n",
    "df_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YRR7mDpVTmOY",
    "outputId": "28bf6a8d-37ff-42de-ea06-e19a9fd7753a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   gender               100000 non-null  object \n",
      " 1   age                  100000 non-null  float64\n",
      " 2   hypertension         100000 non-null  int64  \n",
      " 3   heart_disease        100000 non-null  int64  \n",
      " 4   smoking_history      100000 non-null  object \n",
      " 5   bmi                  100000 non-null  float64\n",
      " 6   HbA1c_level          100000 non-null  float64\n",
      " 7   blood_glucose_level  100000 non-null  int64  \n",
      " 8   diabetes             100000 non-null  int64  \n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 6.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#dispaying the datatypes\n",
    "print(df_pred.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0p9Yu07USDt",
    "outputId": "b11ad048-7fcb-41e9-a3bc-9610a6931fb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                 0\n",
       "age                    0\n",
       "hypertension           0\n",
       "heart_disease          0\n",
       "smoking_history        0\n",
       "bmi                    0\n",
       "HbA1c_level            0\n",
       "blood_glucose_level    0\n",
       "diabetes               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values in the prediction dataset\n",
    "df_pred.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vEQCiYtNtH5H"
   },
   "outputs": [],
   "source": [
    "#Plotting boxplots to check for outliers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Defining the subplot grid\n",
    "def boxplot_plot(df):\n",
    "    for idx, column in enumerate(df.columns):\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.title('Distribution of the ' + column + ' column', fontsize=20)\n",
    "        ax = plt.gca()\n",
    "        sns.boxplot(data=df_diab_012, x=column, ax=ax)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "z7hH83V_yaUP"
   },
   "outputs": [],
   "source": [
    "#Plotting histograms for the columns\n",
    "def histogram_plot(df):\n",
    "  for column in df:\n",
    "        plt.figure(figsize=(20,5))\n",
    "        plt.title('Distribution of the ' + column+ ' column',fontsize=(20))\n",
    "        sns.histplot(data=df, x=column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJ9F4_fD0D5q"
   },
   "source": [
    "## CNN Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sd_3PadW0C4S",
    "outputId": "553f3acf-2691-4f51-ce10-72c2c241ec27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history',\n",
       "       'bmi', 'HbA1c_level', 'blood_glucose_level', 'diabetes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hr-xG-zhVt5w",
    "outputId": "7bd7a8ae-7719-4b85-8b96-38bc8e4aa1e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([80.  , 54.  , 28.  , 36.  , 76.  , 20.  , 44.  , 79.  , 42.  ,\n",
       "       32.  , 53.  , 78.  , 67.  , 15.  , 37.  , 40.  ,  5.  , 69.  ,\n",
       "       72.  ,  4.  , 30.  , 45.  , 43.  , 50.  , 41.  , 26.  , 34.  ,\n",
       "       73.  , 77.  , 66.  , 29.  , 60.  , 38.  ,  3.  , 57.  , 74.  ,\n",
       "       19.  , 46.  , 21.  , 59.  , 27.  , 13.  , 56.  ,  2.  ,  7.  ,\n",
       "       11.  ,  6.  , 55.  ,  9.  , 62.  , 47.  , 12.  , 68.  , 75.  ,\n",
       "       22.  , 58.  , 18.  , 24.  , 17.  , 25.  ,  0.08, 33.  , 16.  ,\n",
       "       61.  , 31.  ,  8.  , 49.  , 39.  , 65.  , 14.  , 70.  ,  0.56,\n",
       "       48.  , 51.  , 71.  ,  0.88, 64.  , 63.  , 52.  ,  0.16, 10.  ,\n",
       "       35.  , 23.  ,  0.64,  1.16,  1.64,  0.72,  1.88,  1.32,  0.8 ,\n",
       "        1.24,  1.  ,  1.8 ,  0.48,  1.56,  1.08,  0.24,  1.4 ,  0.4 ,\n",
       "        0.32,  1.72,  1.48])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.age.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGm8W9rgV3Yg"
   },
   "source": [
    "Where 0 depicts the patient does not have diabetes and 1 depicts the person has diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWvQnc26V1zl",
    "outputId": "d49bafe8-1b5c-4cc0-b7c5-6426fd5ecad6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                 0\n",
       "age                    0\n",
       "hypertension           0\n",
       "heart_disease          0\n",
       "smoking_history        0\n",
       "bmi                    0\n",
       "HbA1c_level            0\n",
       "blood_glucose_level    0\n",
       "diabetes               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for missing values\n",
    "df_pred.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SYQpLSZlWuJ4"
   },
   "outputs": [],
   "source": [
    "#Defining a function to determine the threshold of the outliers\n",
    "def outlier_thresholds(dataframe, variable):\n",
    "    quartile1 = dataframe[variable].quantile(0.10)\n",
    "    quartile3 = dataframe[variable].quantile(0.90)\n",
    "    interquantile_range = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * interquantile_range\n",
    "    low_limit = quartile1 - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PxpVyMScXG2x"
   },
   "outputs": [],
   "source": [
    "#Determining presence of outliers\n",
    "def has_outliers(dataframe, variable):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n",
    "    if dataframe[(dataframe[variable] < low_limit) | (dataframe[variable] > up_limit)].any(axis=None):\n",
    "        print(variable, \"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pOVkn3oKdjVw",
    "outputId": "2fbfefdf-15ca-4eca-80ac-0efec2902f59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.hypertension.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kU-ZZ8VKYaU4",
    "outputId": "099b3e5c-6405-43f9-9bf6-c843267640b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmi yes\n"
     ]
    }
   ],
   "source": [
    "# Looping through each column in the DataFrame and check for outliers\n",
    "for col in df_pred.columns:\n",
    "  if col not in ['gender','smoking_history','diabetes','heart_disease','hypertension']:\n",
    "    has_outliers(df_pred, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BSLd4lPfY2iI"
   },
   "outputs": [],
   "source": [
    "#Writing a function to set a threshold to cap the outliers\n",
    "def replace_with_thresholds(dataframe, numeric_columns):\n",
    "    for variable in numeric_columns:\n",
    "        low_limit, up_limit = outlier_thresholds(dataframe, variable)\n",
    "        dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n",
    "        dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jiDjEHSUZTZN"
   },
   "outputs": [],
   "source": [
    "#Replacing the outliers with the thresholds for the numeric columns.\n",
    "Numeric_col = [col for col in df_pred.columns if col not in ['gender','smoking_history','diabetes','heart_disease','hypertension']]\n",
    "replace_with_thresholds(df_pred, Numeric_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Vw2uk_G7ZHLt"
   },
   "outputs": [],
   "source": [
    "#Confirming if the outliers have been resolved\n",
    "for col in df_pred.columns:\n",
    "  if col not in ['gender','smoking_history','diabetes','heart_disease','hypertension']:\n",
    "    has_outliers(df_pred, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFj8rptcZsqj"
   },
   "source": [
    "There are no outliers observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "hPvj4DxMZuTB",
    "outputId": "92a06153-cf63-49be-bb6d-509386a94938"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>5%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>90%</th>\n",
       "      <th>95%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>41.885856</td>\n",
       "      <td>22.516840</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>43.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.0000</td>\n",
       "      <td>80.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hypertension</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.074850</td>\n",
       "      <td>0.263150</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_disease</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.039420</td>\n",
       "      <td>0.194593</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>27.312972</td>\n",
       "      <td>6.589253</td>\n",
       "      <td>10.01</td>\n",
       "      <td>16.82</td>\n",
       "      <td>23.63</td>\n",
       "      <td>27.32</td>\n",
       "      <td>29.58</td>\n",
       "      <td>35.47</td>\n",
       "      <td>39.49</td>\n",
       "      <td>48.7901</td>\n",
       "      <td>59.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HbA1c_level</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.527507</td>\n",
       "      <td>1.070672</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.80</td>\n",
       "      <td>5.80</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>8.8000</td>\n",
       "      <td>9.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>138.058060</td>\n",
       "      <td>40.708136</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>140.00</td>\n",
       "      <td>159.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>280.0000</td>\n",
       "      <td>300.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.278883</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count        mean        std    min     5%     25%  \\\n",
       "age                  100000.0   41.885856  22.516840   0.08   4.00   24.00   \n",
       "hypertension         100000.0    0.074850   0.263150   0.00   0.00    0.00   \n",
       "heart_disease        100000.0    0.039420   0.194593   0.00   0.00    0.00   \n",
       "bmi                  100000.0   27.312972   6.589253  10.01  16.82   23.63   \n",
       "HbA1c_level          100000.0    5.527507   1.070672   3.50   3.50    4.80   \n",
       "blood_glucose_level  100000.0  138.058060  40.708136  80.00  80.00  100.00   \n",
       "diabetes             100000.0    0.085000   0.278883   0.00   0.00    0.00   \n",
       "\n",
       "                        50%     75%     90%     95%       99%      max  \n",
       "age                   43.00   60.00   73.00   80.00   80.0000   80.000  \n",
       "hypertension           0.00    0.00    0.00    1.00    1.0000    1.000  \n",
       "heart_disease          0.00    0.00    0.00    0.00    1.0000    1.000  \n",
       "bmi                   27.32   29.58   35.47   39.49   48.7901   59.905  \n",
       "HbA1c_level            5.80    6.20    6.60    6.60    8.8000    9.000  \n",
       "blood_glucose_level  140.00  159.00  200.00  200.00  280.0000  300.000  \n",
       "diabetes               0.00    0.00    0.00    1.00    1.0000    1.000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying the measures of central tendancy of the dataset\n",
    "df_pred.describe([0.05,0.25,0.50,0.75,0.90,0.95,0.99]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAYCqhBMiye7"
   },
   "source": [
    "## Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PSg936z8wJvl",
    "outputId": "71dcd9b9-ddc1-4161-8cf7-2dce90b833f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1440 - accuracy: 0.9504\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1147 - accuracy: 0.9603\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1115 - accuracy: 0.9615\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1070 - accuracy: 0.9634\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1003 - accuracy: 0.9661\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0966 - accuracy: 0.9673\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0937 - accuracy: 0.9684\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0921 - accuracy: 0.9689\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0901 - accuracy: 0.9697\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0883 - accuracy: 0.9700\n",
      "625/625 [==============================] - 1s 969us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1489 - accuracy: 0.9497\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1159 - accuracy: 0.9595\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1136 - accuracy: 0.9605\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1116 - accuracy: 0.9614\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1079 - accuracy: 0.9632\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1022 - accuracy: 0.9654\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0977 - accuracy: 0.9668\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0944 - accuracy: 0.9682\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0930 - accuracy: 0.9687\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0913 - accuracy: 0.9697\n",
      "625/625 [==============================] - 1s 949us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1483 - accuracy: 0.9500\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1138 - accuracy: 0.9606\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1095 - accuracy: 0.9624\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1052 - accuracy: 0.9642\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1015 - accuracy: 0.9662\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0981 - accuracy: 0.9674\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0944 - accuracy: 0.9687\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0906 - accuracy: 0.9698\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0885 - accuracy: 0.9703\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0865 - accuracy: 0.9707\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1446 - accuracy: 0.9511\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1161 - accuracy: 0.9587\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1142 - accuracy: 0.9600\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1104 - accuracy: 0.9620\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1071 - accuracy: 0.9641\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1038 - accuracy: 0.9658\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0997 - accuracy: 0.9667\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0948 - accuracy: 0.9683\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0913 - accuracy: 0.9687\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0888 - accuracy: 0.9692\n",
      "625/625 [==============================] - 1s 965us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1480 - accuracy: 0.9501\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1162 - accuracy: 0.9592\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1137 - accuracy: 0.9605\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1100 - accuracy: 0.9628\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1062 - accuracy: 0.9645\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1035 - accuracy: 0.9662\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1007 - accuracy: 0.9673\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0972 - accuracy: 0.9680\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0931 - accuracy: 0.9689\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.0901 - accuracy: 0.9696\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Precision Scores: [0.9877085162423178, 0.9908256880733946, 0.9911347517730497, 0.9826238053866203, 0.9681309216192937]\n",
      "Mean Precision: 0.9840847366189351\n",
      "Recall Scores: [0.6586651053864169, 0.650210716435882, 0.6417910447761194, 0.6672566371681415, 0.6635182998819362]\n",
      "Mean Recall: 0.6562883607296992\n",
      "F1 Scores: [0.7903055848261328, 0.7851690294438387, 0.7790940766550523, 0.7947997189037245, 0.7873905429071804]\n",
      "Mean F1-score: 0.7873517905471857\n"
     ]
    }
   ],
   "source": [
    "# Splitting Data into Features and Labels\n",
    "X = df_pred.drop(['diabetes'], axis=1)  # Replace 'target_column' with the actual target column name\n",
    "y = df_pred['diabetes']\n",
    "\n",
    "# Label Encoding for Categorical Columns\n",
    "label_encoder = LabelEncoder()\n",
    "X_encoded = X.copy()\n",
    "for col in X_encoded.columns:\n",
    "    if X_encoded[col].dtype == 'object':\n",
    "        X_encoded[col] = label_encoder.fit_transform(X_encoded[col])\n",
    "\n",
    "# Feature Scaling (MinMax Scaling)\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded)\n",
    "\n",
    "# Model Hyperparameters\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "n_splits = 5\n",
    "\n",
    "# Performing Cross-Validation\n",
    "cv = KFold(n_splits=n_splits, shuffle=True, random_state=42)  # 5-fold cross-validation\n",
    "scoring = {'precision': 'precision', 'recall': 'recall', 'f1': 'f1'}\n",
    "precision_scores, recall_scores, f1_scores = [], [], []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Model Selection and Building\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_shape=(X_scaled.shape[1],)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # For binary classification, use 'sigmoid' activation for the output layer\n",
    "\n",
    "    # Model Compilation\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Model Training\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    # Model Evaluation (Precision, Recall, F1-score)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)  # Converting the probabilities to binary predictions\n",
    "\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "\n",
    "# Calculating the Mean and Standard Deviation of Evaluation Metrics\n",
    "print(\"Precision Scores:\", precision_scores)\n",
    "print(\"Mean Precision:\", np.mean(precision_scores))\n",
    "print(\"Recall Scores:\", recall_scores)\n",
    "print(\"Mean Recall:\", np.mean(recall_scores))\n",
    "print(\"F1 Scores:\", f1_scores)\n",
    "print(\"Mean F1-score:\", np.mean(f1_scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmH2l-VdjQwt"
   },
   "source": [
    "The results obtained before tuning are as follows:\n",
    "---\n",
    "Mean Precision: 0.9527796794625936\n",
    "---\n",
    "Mean Recall: 0.6628011196639126\n",
    "---\n",
    "Mean F1-score: 0.7778072381482287\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYoThefmhKyq"
   },
   "source": [
    "Plotting for the Training and Validation Loss graphs to check for underfitting and overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TU01qtyOjE1u"
   },
   "source": [
    "Performing hyper parameter tuning using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IZBmk8u12V3U",
    "outputId": "aa459764-936c-43c7-d72f-3d83f5dc6a6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1432 - accuracy: 0.9522 - val_loss: 0.1169 - val_accuracy: 0.9589\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1160 - accuracy: 0.9597 - val_loss: 0.1138 - val_accuracy: 0.9599\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1147 - accuracy: 0.9602 - val_loss: 0.1174 - val_accuracy: 0.9599\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1134 - accuracy: 0.9615 - val_loss: 0.1117 - val_accuracy: 0.9614\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1108 - accuracy: 0.9623 - val_loss: 0.1067 - val_accuracy: 0.9632\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1042 - accuracy: 0.9645 - val_loss: 0.1026 - val_accuracy: 0.9640\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1003 - accuracy: 0.9658 - val_loss: 0.1004 - val_accuracy: 0.9644\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0980 - accuracy: 0.9662 - val_loss: 0.0969 - val_accuracy: 0.9660\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0954 - accuracy: 0.9669 - val_loss: 0.0992 - val_accuracy: 0.9645\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0933 - accuracy: 0.9675 - val_loss: 0.0917 - val_accuracy: 0.9679\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0909 - accuracy: 0.9689 - val_loss: 0.0889 - val_accuracy: 0.9692\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0890 - accuracy: 0.9693 - val_loss: 0.0903 - val_accuracy: 0.9695\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0875 - accuracy: 0.9698 - val_loss: 0.0864 - val_accuracy: 0.9706\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0864 - accuracy: 0.9701 - val_loss: 0.0845 - val_accuracy: 0.9708\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0858 - accuracy: 0.9705 - val_loss: 0.0839 - val_accuracy: 0.9713\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0848 - accuracy: 0.9709 - val_loss: 0.0833 - val_accuracy: 0.9719\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0843 - accuracy: 0.9708 - val_loss: 0.0859 - val_accuracy: 0.9704\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0839 - accuracy: 0.9711 - val_loss: 0.0823 - val_accuracy: 0.9719\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0841 - accuracy: 0.9708 - val_loss: 0.0819 - val_accuracy: 0.9722\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0835 - accuracy: 0.9712 - val_loss: 0.0838 - val_accuracy: 0.9707\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0832 - accuracy: 0.9715 - val_loss: 0.0822 - val_accuracy: 0.9718\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0830 - accuracy: 0.9714 - val_loss: 0.0826 - val_accuracy: 0.9722\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0827 - accuracy: 0.9714 - val_loss: 0.0828 - val_accuracy: 0.9714\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0828 - accuracy: 0.9713 - val_loss: 0.0811 - val_accuracy: 0.9722\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0826 - accuracy: 0.9714 - val_loss: 0.0817 - val_accuracy: 0.9719\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0827 - accuracy: 0.9715 - val_loss: 0.0822 - val_accuracy: 0.9719\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0823 - accuracy: 0.9714 - val_loss: 0.0811 - val_accuracy: 0.9721\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0824 - accuracy: 0.9715 - val_loss: 0.0829 - val_accuracy: 0.9721\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0820 - accuracy: 0.9717 - val_loss: 0.0813 - val_accuracy: 0.9721\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0828 - accuracy: 0.9711 - val_loss: 0.0840 - val_accuracy: 0.9706\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0823 - accuracy: 0.9716 - val_loss: 0.0819 - val_accuracy: 0.9718\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0820 - accuracy: 0.9716 - val_loss: 0.0826 - val_accuracy: 0.9721\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0818 - accuracy: 0.9716 - val_loss: 0.0805 - val_accuracy: 0.9722\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0822 - accuracy: 0.9714 - val_loss: 0.0812 - val_accuracy: 0.9722\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0819 - accuracy: 0.9717 - val_loss: 0.0818 - val_accuracy: 0.9718\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0819 - accuracy: 0.9715 - val_loss: 0.0815 - val_accuracy: 0.9720\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0816 - accuracy: 0.9718 - val_loss: 0.0814 - val_accuracy: 0.9721\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0818 - accuracy: 0.9715 - val_loss: 0.0808 - val_accuracy: 0.9724\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0829 - accuracy: 0.9712 - val_loss: 0.0808 - val_accuracy: 0.9725\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0813 - accuracy: 0.9718 - val_loss: 0.0819 - val_accuracy: 0.9721\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0817 - accuracy: 0.9717 - val_loss: 0.0817 - val_accuracy: 0.9724\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0817 - accuracy: 0.9715 - val_loss: 0.0814 - val_accuracy: 0.9720\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0815 - accuracy: 0.9717 - val_loss: 0.0816 - val_accuracy: 0.9717\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0823 - accuracy: 0.9714 - val_loss: 0.0987 - val_accuracy: 0.9630\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0821 - accuracy: 0.9714 - val_loss: 0.0808 - val_accuracy: 0.9722\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0812 - accuracy: 0.9718 - val_loss: 0.0803 - val_accuracy: 0.9722\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0814 - accuracy: 0.9718 - val_loss: 0.0809 - val_accuracy: 0.9721\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0817 - accuracy: 0.9717 - val_loss: 0.0810 - val_accuracy: 0.9725\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0818 - accuracy: 0.9715 - val_loss: 0.0817 - val_accuracy: 0.9717\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0816 - accuracy: 0.9718 - val_loss: 0.0805 - val_accuracy: 0.9724\n",
      "625/625 [==============================] - 1s 925us/step\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1442 - accuracy: 0.9521 - val_loss: 0.1147 - val_accuracy: 0.9596\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1161 - accuracy: 0.9593 - val_loss: 0.1218 - val_accuracy: 0.9583\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1137 - accuracy: 0.9604 - val_loss: 0.1111 - val_accuracy: 0.9604\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1113 - accuracy: 0.9619 - val_loss: 0.1115 - val_accuracy: 0.9620\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1091 - accuracy: 0.9629 - val_loss: 0.1098 - val_accuracy: 0.9622\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1076 - accuracy: 0.9637 - val_loss: 0.1070 - val_accuracy: 0.9639\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1064 - accuracy: 0.9638 - val_loss: 0.1061 - val_accuracy: 0.9649\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1045 - accuracy: 0.9641 - val_loss: 0.0997 - val_accuracy: 0.9659\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1013 - accuracy: 0.9647 - val_loss: 0.1020 - val_accuracy: 0.9631\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0995 - accuracy: 0.9655 - val_loss: 0.1039 - val_accuracy: 0.9633\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0989 - accuracy: 0.9661 - val_loss: 0.1015 - val_accuracy: 0.9647\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0973 - accuracy: 0.9663 - val_loss: 0.0962 - val_accuracy: 0.9667\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0962 - accuracy: 0.9673 - val_loss: 0.0932 - val_accuracy: 0.9682\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0938 - accuracy: 0.9681 - val_loss: 0.0925 - val_accuracy: 0.9678\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0915 - accuracy: 0.9686 - val_loss: 0.0894 - val_accuracy: 0.9706\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0896 - accuracy: 0.9689 - val_loss: 0.0881 - val_accuracy: 0.9694\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0880 - accuracy: 0.9698 - val_loss: 0.0877 - val_accuracy: 0.9704\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0869 - accuracy: 0.9698 - val_loss: 0.0848 - val_accuracy: 0.9711\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0859 - accuracy: 0.9704 - val_loss: 0.0890 - val_accuracy: 0.9681\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0854 - accuracy: 0.9704 - val_loss: 0.0852 - val_accuracy: 0.9696\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0848 - accuracy: 0.9709 - val_loss: 0.0845 - val_accuracy: 0.9701\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0845 - accuracy: 0.9712 - val_loss: 0.0900 - val_accuracy: 0.9681\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0841 - accuracy: 0.9710 - val_loss: 0.0833 - val_accuracy: 0.9718\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0836 - accuracy: 0.9714 - val_loss: 0.0829 - val_accuracy: 0.9714\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0835 - accuracy: 0.9713 - val_loss: 0.0842 - val_accuracy: 0.9712\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0835 - accuracy: 0.9714 - val_loss: 0.0845 - val_accuracy: 0.9703\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0830 - accuracy: 0.9715 - val_loss: 0.0822 - val_accuracy: 0.9719\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0828 - accuracy: 0.9715 - val_loss: 0.0827 - val_accuracy: 0.9713\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0828 - accuracy: 0.9716 - val_loss: 0.0828 - val_accuracy: 0.9714\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0827 - accuracy: 0.9717 - val_loss: 0.0828 - val_accuracy: 0.9715\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0824 - accuracy: 0.9718 - val_loss: 0.0819 - val_accuracy: 0.9717\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0824 - accuracy: 0.9716 - val_loss: 0.0818 - val_accuracy: 0.9718\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0823 - accuracy: 0.9718 - val_loss: 0.0817 - val_accuracy: 0.9718\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0821 - accuracy: 0.9717 - val_loss: 0.0824 - val_accuracy: 0.9718\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0824 - accuracy: 0.9715 - val_loss: 0.0830 - val_accuracy: 0.9715\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0819 - accuracy: 0.9718 - val_loss: 0.0834 - val_accuracy: 0.9721\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0825 - accuracy: 0.9714 - val_loss: 0.0826 - val_accuracy: 0.9719\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0822 - accuracy: 0.9716 - val_loss: 0.0820 - val_accuracy: 0.9716\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0821 - accuracy: 0.9717 - val_loss: 0.0819 - val_accuracy: 0.9715\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0821 - accuracy: 0.9716 - val_loss: 0.0872 - val_accuracy: 0.9685\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0816 - accuracy: 0.9719 - val_loss: 0.0821 - val_accuracy: 0.9715\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0817 - accuracy: 0.9719 - val_loss: 0.0814 - val_accuracy: 0.9719\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0817 - accuracy: 0.9719 - val_loss: 0.0817 - val_accuracy: 0.9718\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0817 - accuracy: 0.9718 - val_loss: 0.0822 - val_accuracy: 0.9717\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0820 - accuracy: 0.9714 - val_loss: 0.0842 - val_accuracy: 0.9703\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0823 - accuracy: 0.9715 - val_loss: 0.0845 - val_accuracy: 0.9708\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0819 - accuracy: 0.9716 - val_loss: 0.0818 - val_accuracy: 0.9715\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0817 - accuracy: 0.9717 - val_loss: 0.0816 - val_accuracy: 0.9718\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0818 - accuracy: 0.9719 - val_loss: 0.0817 - val_accuracy: 0.9719\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0816 - accuracy: 0.9716 - val_loss: 0.0824 - val_accuracy: 0.9715\n",
      "625/625 [==============================] - 1s 987us/step\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1448 - accuracy: 0.9522 - val_loss: 0.1162 - val_accuracy: 0.9604\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1151 - accuracy: 0.9593 - val_loss: 0.1137 - val_accuracy: 0.9621\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1100 - accuracy: 0.9626 - val_loss: 0.1102 - val_accuracy: 0.9638\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1065 - accuracy: 0.9638 - val_loss: 0.1037 - val_accuracy: 0.9663\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1025 - accuracy: 0.9653 - val_loss: 0.1025 - val_accuracy: 0.9657\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0993 - accuracy: 0.9667 - val_loss: 0.1048 - val_accuracy: 0.9647\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0965 - accuracy: 0.9677 - val_loss: 0.1016 - val_accuracy: 0.9662\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0944 - accuracy: 0.9687 - val_loss: 0.0977 - val_accuracy: 0.9673\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0924 - accuracy: 0.9690 - val_loss: 0.0927 - val_accuracy: 0.9680\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0895 - accuracy: 0.9696 - val_loss: 0.0896 - val_accuracy: 0.9699\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0880 - accuracy: 0.9697 - val_loss: 0.0895 - val_accuracy: 0.9689\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0864 - accuracy: 0.9703 - val_loss: 0.0878 - val_accuracy: 0.9693\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0861 - accuracy: 0.9700 - val_loss: 0.0861 - val_accuracy: 0.9704\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0853 - accuracy: 0.9706 - val_loss: 0.0870 - val_accuracy: 0.9701\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0849 - accuracy: 0.9706 - val_loss: 0.0898 - val_accuracy: 0.9679\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0844 - accuracy: 0.9706 - val_loss: 0.0867 - val_accuracy: 0.9704\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0841 - accuracy: 0.9710 - val_loss: 0.0865 - val_accuracy: 0.9693\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0842 - accuracy: 0.9708 - val_loss: 0.0851 - val_accuracy: 0.9707\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0837 - accuracy: 0.9711 - val_loss: 0.0891 - val_accuracy: 0.9685\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0832 - accuracy: 0.9714 - val_loss: 0.0874 - val_accuracy: 0.9703\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0835 - accuracy: 0.9712 - val_loss: 0.0847 - val_accuracy: 0.9709\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0831 - accuracy: 0.9713 - val_loss: 0.0846 - val_accuracy: 0.9703\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0829 - accuracy: 0.9714 - val_loss: 0.0890 - val_accuracy: 0.9675\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0827 - accuracy: 0.9715 - val_loss: 0.0843 - val_accuracy: 0.9711\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0827 - accuracy: 0.9713 - val_loss: 0.0846 - val_accuracy: 0.9704\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0828 - accuracy: 0.9714 - val_loss: 0.0850 - val_accuracy: 0.9708\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0820 - accuracy: 0.9718 - val_loss: 0.0960 - val_accuracy: 0.9633\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0823 - accuracy: 0.9717 - val_loss: 0.0852 - val_accuracy: 0.9711\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0819 - accuracy: 0.9718 - val_loss: 0.0853 - val_accuracy: 0.9704\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0821 - accuracy: 0.9719 - val_loss: 0.0840 - val_accuracy: 0.9712\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0817 - accuracy: 0.9717 - val_loss: 0.0856 - val_accuracy: 0.9709\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0822 - accuracy: 0.9716 - val_loss: 0.0842 - val_accuracy: 0.9710\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0819 - accuracy: 0.9718 - val_loss: 0.0972 - val_accuracy: 0.9650\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0819 - accuracy: 0.9719 - val_loss: 0.0850 - val_accuracy: 0.9700\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.0819 - accuracy: 0.9719 - val_loss: 0.0840 - val_accuracy: 0.9710\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0819 - accuracy: 0.9720 - val_loss: 0.0838 - val_accuracy: 0.9709\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0816 - accuracy: 0.9720 - val_loss: 0.0838 - val_accuracy: 0.9712\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0817 - accuracy: 0.9717 - val_loss: 0.0837 - val_accuracy: 0.9711\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0815 - accuracy: 0.9720 - val_loss: 0.0850 - val_accuracy: 0.9700\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0816 - accuracy: 0.9719 - val_loss: 0.0855 - val_accuracy: 0.9714\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0819 - accuracy: 0.9716 - val_loss: 0.0839 - val_accuracy: 0.9710\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0811 - accuracy: 0.9720 - val_loss: 0.0845 - val_accuracy: 0.9711\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0821 - accuracy: 0.9716 - val_loss: 0.0839 - val_accuracy: 0.9714\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0819 - accuracy: 0.9717 - val_loss: 0.0851 - val_accuracy: 0.9711\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0813 - accuracy: 0.9721 - val_loss: 0.0831 - val_accuracy: 0.9707\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0811 - accuracy: 0.9721 - val_loss: 0.0841 - val_accuracy: 0.9711\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0813 - accuracy: 0.9719 - val_loss: 0.0843 - val_accuracy: 0.9711\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0810 - accuracy: 0.9721 - val_loss: 0.0842 - val_accuracy: 0.9710\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0810 - accuracy: 0.9721 - val_loss: 0.0835 - val_accuracy: 0.9714\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0807 - accuracy: 0.9722 - val_loss: 0.0843 - val_accuracy: 0.9714\n",
      "625/625 [==============================] - 1s 925us/step\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1451 - accuracy: 0.9521 - val_loss: 0.1159 - val_accuracy: 0.9584\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1167 - accuracy: 0.9586 - val_loss: 0.1164 - val_accuracy: 0.9577\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1156 - accuracy: 0.9597 - val_loss: 0.1186 - val_accuracy: 0.9616\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1125 - accuracy: 0.9614 - val_loss: 0.1069 - val_accuracy: 0.9632\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1110 - accuracy: 0.9625 - val_loss: 0.1186 - val_accuracy: 0.9549\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1099 - accuracy: 0.9629 - val_loss: 0.1142 - val_accuracy: 0.9573\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1079 - accuracy: 0.9632 - val_loss: 0.1007 - val_accuracy: 0.9660\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1055 - accuracy: 0.9646 - val_loss: 0.1026 - val_accuracy: 0.9649\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1032 - accuracy: 0.9650 - val_loss: 0.0984 - val_accuracy: 0.9676\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1011 - accuracy: 0.9656 - val_loss: 0.0973 - val_accuracy: 0.9676\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0990 - accuracy: 0.9667 - val_loss: 0.0932 - val_accuracy: 0.9696\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0970 - accuracy: 0.9674 - val_loss: 0.0923 - val_accuracy: 0.9682\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0943 - accuracy: 0.9683 - val_loss: 0.0873 - val_accuracy: 0.9710\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0914 - accuracy: 0.9688 - val_loss: 0.0850 - val_accuracy: 0.9707\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0893 - accuracy: 0.9690 - val_loss: 0.0848 - val_accuracy: 0.9711\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0880 - accuracy: 0.9696 - val_loss: 0.0834 - val_accuracy: 0.9706\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0870 - accuracy: 0.9699 - val_loss: 0.0885 - val_accuracy: 0.9676\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0868 - accuracy: 0.9700 - val_loss: 0.0804 - val_accuracy: 0.9722\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0860 - accuracy: 0.9704 - val_loss: 0.0823 - val_accuracy: 0.9708\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0857 - accuracy: 0.9705 - val_loss: 0.0814 - val_accuracy: 0.9720\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0858 - accuracy: 0.9701 - val_loss: 0.0801 - val_accuracy: 0.9725\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0851 - accuracy: 0.9705 - val_loss: 0.0800 - val_accuracy: 0.9719\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0849 - accuracy: 0.9706 - val_loss: 0.0798 - val_accuracy: 0.9727\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0849 - accuracy: 0.9705 - val_loss: 0.0799 - val_accuracy: 0.9724\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0842 - accuracy: 0.9709 - val_loss: 0.0806 - val_accuracy: 0.9718\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0842 - accuracy: 0.9709 - val_loss: 0.0796 - val_accuracy: 0.9726\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0843 - accuracy: 0.9709 - val_loss: 0.0788 - val_accuracy: 0.9726\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0844 - accuracy: 0.9708 - val_loss: 0.0794 - val_accuracy: 0.9722\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0840 - accuracy: 0.9709 - val_loss: 0.0793 - val_accuracy: 0.9719\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0841 - accuracy: 0.9711 - val_loss: 0.0785 - val_accuracy: 0.9728\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0836 - accuracy: 0.9714 - val_loss: 0.0787 - val_accuracy: 0.9725\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0838 - accuracy: 0.9711 - val_loss: 0.0784 - val_accuracy: 0.9727\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0839 - accuracy: 0.9712 - val_loss: 0.0791 - val_accuracy: 0.9724\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0837 - accuracy: 0.9709 - val_loss: 0.0933 - val_accuracy: 0.9639\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0842 - accuracy: 0.9708 - val_loss: 0.0795 - val_accuracy: 0.9721\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0832 - accuracy: 0.9712 - val_loss: 0.0816 - val_accuracy: 0.9720\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0834 - accuracy: 0.9713 - val_loss: 0.0782 - val_accuracy: 0.9724\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0828 - accuracy: 0.9715 - val_loss: 0.0785 - val_accuracy: 0.9727\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0829 - accuracy: 0.9713 - val_loss: 0.0784 - val_accuracy: 0.9730\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0831 - accuracy: 0.9714 - val_loss: 0.0780 - val_accuracy: 0.9729\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.0831 - accuracy: 0.9715 - val_loss: 0.0808 - val_accuracy: 0.9721\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0828 - accuracy: 0.9715 - val_loss: 0.0784 - val_accuracy: 0.9726\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0830 - accuracy: 0.9714 - val_loss: 0.0788 - val_accuracy: 0.9729\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0831 - accuracy: 0.9712 - val_loss: 0.0796 - val_accuracy: 0.9722\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0829 - accuracy: 0.9716 - val_loss: 0.0784 - val_accuracy: 0.9729\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0829 - accuracy: 0.9713 - val_loss: 0.0793 - val_accuracy: 0.9719\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0827 - accuracy: 0.9714 - val_loss: 0.0815 - val_accuracy: 0.9715\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0826 - accuracy: 0.9717 - val_loss: 0.0778 - val_accuracy: 0.9729\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0826 - accuracy: 0.9717 - val_loss: 0.0780 - val_accuracy: 0.9732\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0832 - accuracy: 0.9711 - val_loss: 0.0777 - val_accuracy: 0.9730\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 7s 2ms/step - loss: 0.1453 - accuracy: 0.9500 - val_loss: 0.1160 - val_accuracy: 0.9590\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1154 - accuracy: 0.9601 - val_loss: 0.1149 - val_accuracy: 0.9589\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1126 - accuracy: 0.9616 - val_loss: 0.1100 - val_accuracy: 0.9620\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1089 - accuracy: 0.9629 - val_loss: 0.1051 - val_accuracy: 0.9643\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1019 - accuracy: 0.9656 - val_loss: 0.0989 - val_accuracy: 0.9665\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0964 - accuracy: 0.9676 - val_loss: 0.0978 - val_accuracy: 0.9663\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0932 - accuracy: 0.9686 - val_loss: 0.0936 - val_accuracy: 0.9675\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0908 - accuracy: 0.9693 - val_loss: 0.0918 - val_accuracy: 0.9696\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0877 - accuracy: 0.9698 - val_loss: 0.0922 - val_accuracy: 0.9692\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0867 - accuracy: 0.9698 - val_loss: 0.0881 - val_accuracy: 0.9696\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0853 - accuracy: 0.9707 - val_loss: 0.0899 - val_accuracy: 0.9697\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0846 - accuracy: 0.9707 - val_loss: 0.0878 - val_accuracy: 0.9707\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0845 - accuracy: 0.9708 - val_loss: 0.0865 - val_accuracy: 0.9708\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0839 - accuracy: 0.9707 - val_loss: 0.0868 - val_accuracy: 0.9710\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0836 - accuracy: 0.9711 - val_loss: 0.0878 - val_accuracy: 0.9705\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0828 - accuracy: 0.9713 - val_loss: 0.0858 - val_accuracy: 0.9708\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0828 - accuracy: 0.9712 - val_loss: 0.0896 - val_accuracy: 0.9689\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0832 - accuracy: 0.9710 - val_loss: 0.0967 - val_accuracy: 0.9651\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0830 - accuracy: 0.9712 - val_loss: 0.0854 - val_accuracy: 0.9711\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0824 - accuracy: 0.9713 - val_loss: 0.0860 - val_accuracy: 0.9708\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0824 - accuracy: 0.9711 - val_loss: 0.0874 - val_accuracy: 0.9697\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0823 - accuracy: 0.9712 - val_loss: 0.0869 - val_accuracy: 0.9702\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0823 - accuracy: 0.9714 - val_loss: 0.0864 - val_accuracy: 0.9700\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0821 - accuracy: 0.9715 - val_loss: 0.0873 - val_accuracy: 0.9688\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0827 - accuracy: 0.9711 - val_loss: 0.0861 - val_accuracy: 0.9714\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0815 - accuracy: 0.9719 - val_loss: 0.0854 - val_accuracy: 0.9707\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0818 - accuracy: 0.9716 - val_loss: 0.0848 - val_accuracy: 0.9715\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0815 - accuracy: 0.9718 - val_loss: 0.0858 - val_accuracy: 0.9704\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0815 - accuracy: 0.9716 - val_loss: 0.0873 - val_accuracy: 0.9698\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0819 - accuracy: 0.9714 - val_loss: 0.0952 - val_accuracy: 0.9667\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0815 - accuracy: 0.9716 - val_loss: 0.0872 - val_accuracy: 0.9692\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0818 - accuracy: 0.9715 - val_loss: 0.0858 - val_accuracy: 0.9711\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0814 - accuracy: 0.9718 - val_loss: 0.0845 - val_accuracy: 0.9716\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0812 - accuracy: 0.9719 - val_loss: 0.0850 - val_accuracy: 0.9715\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0818 - accuracy: 0.9716 - val_loss: 0.0848 - val_accuracy: 0.9715\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0812 - accuracy: 0.9720 - val_loss: 0.0922 - val_accuracy: 0.9667\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0814 - accuracy: 0.9720 - val_loss: 0.0845 - val_accuracy: 0.9714\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0814 - accuracy: 0.9716 - val_loss: 0.0842 - val_accuracy: 0.9714\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0814 - accuracy: 0.9718 - val_loss: 0.0848 - val_accuracy: 0.9713\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0809 - accuracy: 0.9720 - val_loss: 0.0855 - val_accuracy: 0.9711\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0813 - accuracy: 0.9717 - val_loss: 0.0875 - val_accuracy: 0.9700\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0808 - accuracy: 0.9718 - val_loss: 0.0847 - val_accuracy: 0.9707\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0807 - accuracy: 0.9721 - val_loss: 0.0855 - val_accuracy: 0.9708\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0811 - accuracy: 0.9718 - val_loss: 0.0854 - val_accuracy: 0.9716\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0807 - accuracy: 0.9719 - val_loss: 0.0860 - val_accuracy: 0.9714\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0812 - accuracy: 0.9718 - val_loss: 0.0868 - val_accuracy: 0.9707\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0812 - accuracy: 0.9718 - val_loss: 0.0844 - val_accuracy: 0.9715\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0806 - accuracy: 0.9720 - val_loss: 0.0867 - val_accuracy: 0.9703\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0809 - accuracy: 0.9719 - val_loss: 0.0874 - val_accuracy: 0.9699\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0808 - accuracy: 0.9720 - val_loss: 0.0887 - val_accuracy: 0.9693\n",
      "625/625 [==============================] - 1s 930us/step\n",
      "Precision Scores: [0.9906621392190152, 0.9901168014375562, 0.9818780889621087, 0.9840871021775545, 0.9864864864864865]\n",
      "Mean Precision: 0.9866461236565442\n",
      "Recall Scores: [0.6832552693208431, 0.6634557495484648, 0.6842709529276694, 0.6932153392330384, 0.6463990554899646]\n",
      "Mean Recall: 0.6741192733039961\n",
      "F1 Scores: [0.8087318087318088, 0.7945205479452055, 0.8064952638700946, 0.8134302526825892, 0.7810271041369472]\n",
      "Mean F1-score: 0.800840995473329\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Hyperparameters\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "n_splits = 5\n",
    "\n",
    "# Perform Cross-Validation\n",
    "cv = KFold(n_splits=n_splits, shuffle=True, random_state=42)  # 5-fold cross-validation\n",
    "scoring = {'precision': 'precision', 'recall': 'recall', 'f1': 'f1'}\n",
    "precision_scores, recall_scores, f1_scores = [], [], []\n",
    "training_losses, validation_losses = [], []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Step 4: Model Selection and Building\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_shape=(X_scaled.shape[1],)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # For binary classification, use 'sigmoid' activation for the output layer\n",
    "\n",
    "    # Step 5: Model Compilation\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Step 6: Model Training\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
    "\n",
    "    # Store Training and Validation Losses\n",
    "    training_losses.append(history.history['loss'])\n",
    "    validation_losses.append(history.history['val_loss'])\n",
    "\n",
    "    # Step 7: Model Evaluation (Precision, Recall, F1-score)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "\n",
    "# Calculate Mean and Standard Deviation of Evaluation Metrics\n",
    "print(\"Precision Scores:\", precision_scores)\n",
    "print(\"Mean Precision:\", np.mean(precision_scores))\n",
    "print(\"Recall Scores:\", recall_scores)\n",
    "print(\"Mean Recall:\", np.mean(recall_scores))\n",
    "print(\"F1 Scores:\", f1_scores)\n",
    "print(\"Mean F1-score:\", np.mean(f1_scores))\n",
    "\n",
    "# Plot Training and Validation Loss Curves\n",
    "mean_training_loss = np.mean(training_losses, axis=0)\n",
    "mean_validation_loss = np.mean(validation_losses, axis=0)\n",
    "epochs_range = range(1, epochs + 1)\n",
    "\n",
    "#plotting for the Train and Validation curves\n",
    "\n",
    "plt.plot(epochs_range, mean_training_loss, label='Training Loss')\n",
    "plt.plot(epochs_range, mean_validation_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxgWjmcejeLF"
   },
   "source": [
    "After parameter tuning using cross-validation, the results are as follows:\n",
    "---\n",
    "Mean Precision: 0.9889475375662571\n",
    "---\n",
    "Mean Recall: 0.6756253791827906\n",
    "---\n",
    "Mean F1-score: 0.8027126832856661\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLbzkQ43hWwH"
   },
   "source": [
    "Saving the model in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HVvnXk7JAg8h",
    "outputId": "1cc4628d-8881-423a-bc17-b3a9ad42ed30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Diabetes_CNN_model\\\\CNN_model_diab_pred.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "#Dedfining the directory to save the model\n",
    "save_dir = 'Diabetes_CNN_model'\n",
    "\n",
    "# Creating the directory\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Defining the filename for the model\n",
    "model_filename = 'CNN_model_diab_pred.pkl'\n",
    "\n",
    "# Creating the full file path by joining the directory and filename\n",
    "file_path = os.path.join(save_dir, model_filename)\n",
    "\n",
    "# saving the model using joblib.dump()\n",
    "joblib.dump(model, file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwZmm6vehqyw"
   },
   "source": [
    "Creating a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "KnxclcLOh7la",
    "outputId": "380aa585-e236-41a5-bddb-08b16861aa50"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix  # Import the confusion_matrix function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
    "            yticklabels=['True Negative', 'True Positive'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pG3QTTdwiVS5"
   },
   "source": [
    "We observed the following results:\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "True Negatives - 18288\n",
    "---\n",
    "False Positives - 18\n",
    "---\n",
    "False Negatives - 552\n",
    "---\n",
    "True Positives - 1142\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ffrYqiB3nhqM",
    "outputId": "1b8bf5a7-5cc0-4c23-afa1-378c842ad826"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Saving the best model as a file using joblib\n",
    "CNN_bestmodel = 'best_model.joblib'  # Specify the desired file name\n",
    "joblib.dump(model, CNN_bestmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilIxdbeYiHPP"
   },
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "lK8Czp5st45t"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting the train data to a dataframe to facilitate deployment\n",
    "X_train_1 = pd.DataFrame(X_train)\n",
    "type(X_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sA3WTAYfm1wc",
    "outputId": "cc59c233-01e2-4ccb-f7c3-51b36db0cb98"
   },
   "outputs": [],
   "source": [
    "# Function to preprocess the user input data\n",
    "def preprocess_user_data(user_data):\n",
    "    # Encode gender\n",
    "    user_data['gender'] = user_data['gender'].apply(lambda x: 1 if x.lower() == 'male' else 0)\n",
    "\n",
    "    # Encode smoking_history\n",
    "    smoking_mapping = {\n",
    "        'never': 4,\n",
    "        'No Info': 0,\n",
    "        'current': 1,\n",
    "        'former': 3,\n",
    "        'ever': 2,\n",
    "        'not current': 5\n",
    "    }\n",
    "    user_data['smoking_history'] = user_data['smoking_history'].map(smoking_mapping)\n",
    "\n",
    "    return user_data\n",
    "\n",
    "# Function to take input from the user and make predictions\n",
    "def predict_diabetes(model_):\n",
    "    # Get user input for features\n",
    "    gender = input(\"Enter gender (Male/Female): \")\n",
    "    age = float(input(\"Enter age: \"))\n",
    "    hypertension = int(input(\"Enter hypertension (0 for No, 1 for Yes): \"))\n",
    "    heart_disease = int(input(\"Enter heart disease (0 for No, 1 for Yes): \"))\n",
    "    smoking_history = input(\"Enter smoking history (never/No Info/current/former/ever/not current): \")\n",
    "    bmi = float(input(\"Enter BMI: \"))\n",
    "    hba1c_level = float(input(\"Enter HbA1c level: \"))\n",
    "    blood_glucose_level = int(input(\"Enter blood glucose level: \"))\n",
    "\n",
    "    # Create a DataFrame with the user input\n",
    "    user_data = pd.DataFrame({\n",
    "        'gender': [gender],\n",
    "        'age': [age],\n",
    "        'hypertension': [hypertension],\n",
    "        'heart_disease': [heart_disease],\n",
    "        'smoking_history': [smoking_history],\n",
    "        'bmi': [bmi],\n",
    "        'HbA1c_level': [hba1c_level],\n",
    "        'blood_glucose_level': [blood_glucose_level]\n",
    "    })\n",
    "\n",
    "    # Preprocess user input\n",
    "    user_data = preprocess_user_data(user_data)\n",
    "\n",
    "    # Ensure the user input data has the same columns as the training data\n",
    "    missing_cols = set(X_train_1.columns) - set(user_data.columns)\n",
    "    for col in missing_cols:\n",
    "        user_data[col] = 0\n",
    "\n",
    "    user_data = user_data[X_train_1.columns]\n",
    "\n",
    "    # Use the trained model to make predictions on the preprocessed user input\n",
    "    prediction = model.predict(user_data)[0]\n",
    "\n",
    "    # Interpret the prediction\n",
    "    if prediction < 0.5:\n",
    "        print(\"Based on the input, the person is predicted to NOT have diabetes.\")\n",
    "    else:\n",
    "        print(\"Based on the input, the person is predicted to have diabetes.\")\n",
    "\n",
    "# Call the predict_diabetes function to make predictions\n",
    "predict_diabetes(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_xOI7b1gGm0T",
    "outputId": "04852ddc-2336-4c4b-9280-1b33148b4f15"
   },
   "outputs": [],
   "source": [
    "predict_diabetes(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UL9E-1OwyPBO",
    "outputId": "22e6a014-3cfc-452d-f574-cbab8220de55"
   },
   "outputs": [],
   "source": [
    "# Call the predict_diabetes function to make predictions\n",
    "predict_diabetes(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uwNAtIuHyfxY",
    "outputId": "d8ae62a9-0ce4-4c8f-9294-9d0881565b88"
   },
   "outputs": [],
   "source": [
    "# Call the predict_diabetes function to make predictions\n",
    "predict_diabetes(model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
